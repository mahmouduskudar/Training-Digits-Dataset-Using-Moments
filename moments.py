# -*- coding: utf-8 -*-
"""Moments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hBEwm7sBbmI3t9aOKgmE6yo0aXJPVhHc

# **Number Detection**

# Importing Libraries
"""

import matplotlib.pyplot as plt
import pandas as pd
import cv2 as cv
import numpy as np
import collections
import tensorflow as tf
import seaborn as sns
from sklearn import datasets, svm, metrics
from sklearn.model_selection import train_test_split

"""# Import Dataset"""

digits = datasets.load_digits()

"""# Find Contours for Entire Digits"""

moments_list = []
for image in digits.images:
    digit_unint8 = cv.convertScaleAbs(image, alpha=(255.0))
    _, thresh = cv.threshold(digit_unint8, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)
    counters, hierarchy = cv.findContours(thresh, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)

    digit_moments = []
    for counter in counters:
        moments = cv.moments(counter)
        digit_moments.extend(list(moments.values()))

    moments_list.append(digit_moments)

"""# Padding the Contours Set"""

max_len = max(len(row) for row in moments_list)


# Padding shorter lists of moments with zeros to ensure uniform length
moment_pad = [row + [0] * (max_len - len(row)) for row in moments_list]

moment_pad_array = np.array(moment_pad)

"""# Flatten Moments"""

# Flatten the list of moments
moments_array = np.array(moment_pad)
totalItems = moments_array.shape[1]

df_data = pd.DataFrame(moments_array)
df_data = df_data.astype('float32')

"""# Train the model"""

#split the dataset into train and test
X_train, X_test, y_train, y_test = train_test_split(df_data, digits.target, test_size=0.2, shuffle=False)


# Define and compile the model
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(totalItems, 1)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


# Train the model with the custom callback
model.fit(X_train, y_train, epochs=100)

# Evaluate the final model
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print('\nTest accuracy:', test_acc)

"""# Print Confusion Matrix"""

# Get model predictions
y_pred_probs = model.predict(X_test)

# Convert probabilities to predicted labels
y_pred = np.argmax(y_pred_probs, axis=1)

# Display confusion matrix
conf_matrix = metrics.confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

"""# Show Confusion Matrix"""

# Display confusion matrix as heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()